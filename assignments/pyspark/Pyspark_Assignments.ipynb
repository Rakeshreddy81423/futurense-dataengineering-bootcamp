{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e6f242",
   "metadata": {},
   "source": [
    "# Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f82e9a",
   "metadata": {},
   "source": [
    "## Assignment - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5c3e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f004e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa882a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"SparkApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4454bdca",
   "metadata": {},
   "source": [
    "## Find min and max temperatures in given weather_data\n",
    "### *The data is seperated by one or more spaces. So first transform the data and do the calculations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b2d15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = \"D:/futurense_hadoop-pyspark/labs/dataset/weather/weather_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2f0112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['WBANNO',\n",
    " 'LST_DATE',\n",
    " 'CRX_VN',\n",
    " 'LONGITUDE',\n",
    " 'LATITUDE',\n",
    " 'T_DAILY_MAX',\n",
    " 'T_DAILY_MIN',\n",
    " 'T_DAILY_MEAN',\n",
    " 'T_DAILY_AVG',\n",
    " 'P_DAILY_CALC',\n",
    " 'SOLARAD_DAILY',\n",
    " 'SUR_TEMP_DAILY_TYPE',\n",
    " 'SUR_TEMP_DAILY_MAX',\n",
    " 'SUR_TEMP_DAILY_MIN',\n",
    " 'SUR_TEMP_DAILY_AVG',\n",
    " 'RH_DAILY_MAX',\n",
    " 'RH_DAILY_MIN',\n",
    " 'RH_DAILY_AVG',\n",
    " 'SOIL_MOISTURE_5_DAILY',\n",
    " 'SOIL_MOISTURE_10_DAILY',\n",
    " 'SOIL_MOISTURE_20_DAILY',\n",
    " 'SOIL_MOISTURE_50_DAILY',\n",
    " 'SOIL_MOISTURE_100_DAILY',\n",
    " 'SOIL_TEMP_5_DAILY',\n",
    " 'SOIL_TEMP_10_DAILY',\n",
    " 'SOIL_TEMP_20_DAILY',\n",
    " 'SOIL_TEMP_50_DAILY',\n",
    " 'SOIL_TEMP_100_DAILY']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d14c98",
   "metadata": {},
   "source": [
    "### First read the data remove extra spaces and make it as comma seperated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e42ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.load(path,format=\"csv\")\n",
    "\n",
    "#df = data.withColumn(\"values\", regexp_replace(data.values, \"\\s+\", \",\")).withColumn(\"values\",split(data.value,\",\"))\n",
    "\n",
    "df = data.withColumn(\"_c0\",regexp_replace(data._c0,\"\\s+\",\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8d400",
   "metadata": {},
   "source": [
    "### Split the data based on ',' and store values in respective columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0d2d7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|Min_temp|max_temp|\n",
      "+--------+--------+\n",
      "|    -7.9|    36.0|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "split_data = df.select(split(df._c0, \",\").alias(\"data\"))\n",
    "\n",
    "\n",
    "converted_data = split_data.select(\n",
    "    *[split_data.data.getItem(idx).alias(columns[idx]) for idx in range(len(columns))])\n",
    "    \n",
    "\n",
    "#select the required the columns and type cast them into required datatype     \n",
    "min_max_df = converted_data.select(col(\"T_DAILY_MAX\").cast(FloatType()).alias(\"T_DAILY_MAX\"),col(\"T_DAILY_MIN\").cast(FloatType()).alias(\"T_DAILY_MIN\"))\n",
    "\n",
    "# find the min from the daily_min and max from daily_max\n",
    "min_max_df.agg(min(\"T_DAILY_MIN\").alias(\"Min_temp\"),max(\"T_DAILY_MAX\").alias(\"max_temp\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b3a89",
   "metadata": {},
   "source": [
    "## Find the max and min temperatures in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37d76b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------+\n",
      "|MONTH|Min_temp|Max_temp|\n",
      "+-----+--------+--------+\n",
      "|  May|    14.3|    31.1|\n",
      "|  Jun|     0.0|    33.6|\n",
      "|  Feb|    -3.5|    26.6|\n",
      "|  Mar|    -3.2|    29.1|\n",
      "|  Jan|    -7.9|    26.5|\n",
      "|  Apr|     8.0|    30.8|\n",
      "|  Jul|    19.8|    36.0|\n",
      "+-----+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "months = {'01':'Jan','02':'Feb','03':'Mar','04':'Apr','05':'May','06':'Jun',\n",
    "          '07':'Jul','08':'Aug','09':'Sep','10':'Oct','11':'Nov','12':'Dec'}\n",
    "\n",
    "def find_month_name(month_num):\n",
    "    return months[month_num]\n",
    "\n",
    "month_df = udf(find_month_name,StringType())\n",
    "\n",
    "\n",
    "df = converted_data.withColumn('MONTH',month_df(substring('LST_DATE',5,2)))\\\n",
    "                   .select(\n",
    "                            col('MONTH'),col(\"T_DAILY_MAX\").cast(FloatType()).alias(\"T_DAILY_MAX\"),\n",
    "                            col(\"T_DAILY_MIN\").cast(FloatType()).alias(\"T_DAILY_MIN\")\n",
    "                          )\n",
    "\n",
    "df.groupBy('MONTH').agg(min('T_DAILY_MIN').alias('Min_temp'),max('T_DAILY_MAX').alias('Max_temp')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9ca39",
   "metadata": {},
   "source": [
    "# Assignment-2 \n",
    "## Find the total count of ratings for each type of rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e41efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:/Users/rakes/OneDrive/Desktop/ml-latest-small/ml-latest-small/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "045b3d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|rating|count|\n",
      "+------+-----+\n",
      "|   1.0| 2811|\n",
      "|   4.5| 8551|\n",
      "|   2.5| 5550|\n",
      "|   3.5|13136|\n",
      "|   5.0|13211|\n",
      "|   0.5| 1370|\n",
      "|   4.0|26818|\n",
      "|   1.5| 1791|\n",
      "|   2.0| 7551|\n",
      "|   3.0|20047|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df = spark.read.csv(path,header=True)\n",
    "\n",
    "ratings_df.groupBy('rating').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad6ca89",
   "metadata": {},
   "source": [
    "# Assignment-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993a76e",
   "metadata": {},
   "source": [
    "## Bankmarket- Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c17e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/futurense_hadoop-pyspark/labs/dataset/bankmarket/bankmarketdata.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d231e",
   "metadata": {},
   "source": [
    "### 1.\tLoad data and create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "879e6ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_df = spark.read.csv(path,header=True,sep=';',inferSchema=True)\n",
    "bank_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b33d9c",
   "metadata": {},
   "source": [
    "### 2.\tGive marketing success rate. (No. of people subscribed / total no. of entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1caabe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 11.698480458295547\n"
     ]
    }
   ],
   "source": [
    "total_count = bank_df.count()\n",
    "\n",
    "success_rate = bank_df.filter(bank_df['y'] == 'yes').count() / total_count * 100\n",
    "\n",
    "print(\"Success rate:\",success_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a357a118",
   "metadata": {},
   "source": [
    "   ### 3.Give marketing failure rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59b3b791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure rate: 88.30151954170445\n"
     ]
    }
   ],
   "source": [
    "failure_rate = bank_df.filter(bank_df.y == 'no').count() / total_count * 100\n",
    "\n",
    "print(\"Failure rate:\",failure_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7088f697",
   "metadata": {},
   "source": [
    "### 4.\tMaximum, Mean, and Minimum age of the average targeted customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "258ab032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+\n",
      "|Min_Age|Max_Age|Avg_age|\n",
      "+-------+-------+-------+\n",
      "|     18|     95|  40.94|\n",
      "+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_df.select('age').agg(min(bank_df.age).alias('Min_Age'),\n",
    "                          max(bank_df.age).alias('Max_Age'),\n",
    "                          round(avg(bank_df.age),2).alias('Avg_age')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661bdcdc",
   "metadata": {},
   "source": [
    "### 5.\tCheck the quality of customers by checking the average balance, median balance of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "64525e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|Avg_balance|Median_balance|\n",
      "+-----------+--------------+\n",
      "|    1362.27|           448|\n",
      "+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_df.agg(\n",
    "            round(avg(bank_df.balance),2).alias(\"Avg_balance\"),\n",
    "            percentile_approx(bank_df.balance,0.5).alias(\"Median_balance\")\n",
    "            ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b1fe55",
   "metadata": {},
   "source": [
    "### 6.\tCheck if age matters in marketing subscription for deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d3d559e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "| 18|    7|\n",
      "| 19|   11|\n",
      "| 20|   15|\n",
      "| 21|   22|\n",
      "| 22|   40|\n",
      "| 23|   44|\n",
      "| 24|   68|\n",
      "| 25|  113|\n",
      "| 26|  134|\n",
      "| 27|  141|\n",
      "| 28|  162|\n",
      "| 29|  171|\n",
      "| 30|  217|\n",
      "| 31|  206|\n",
      "| 32|  221|\n",
      "| 33|  210|\n",
      "| 34|  198|\n",
      "| 35|  209|\n",
      "| 36|  195|\n",
      "| 37|  170|\n",
      "+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_df.select('age','y').filter(bank_df['y'] == 'yes').groupBy('age')\\\n",
    "    .count().orderBy('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fd12aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "| 31|  206|\n",
      "| 85|    4|\n",
      "| 65|   21|\n",
      "| 53|   85|\n",
      "| 78|   14|\n",
      "| 34|  198|\n",
      "| 81|    6|\n",
      "| 28|  162|\n",
      "| 76|   16|\n",
      "| 26|  134|\n",
      "| 27|  141|\n",
      "| 44|   93|\n",
      "| 22|   40|\n",
      "| 93|    2|\n",
      "| 47|  113|\n",
      "| 52|   85|\n",
      "| 86|    4|\n",
      "| 40|  116|\n",
      "| 20|   15|\n",
      "| 57|   78|\n",
      "+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_df.select('age','y').filter(bank_df.y == 'yes').groupBy('age').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e93f54",
   "metadata": {},
   "source": [
    "### 7.\tCheck if marital status mattered for subscription to deposit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ecfd227f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "| marital|count|\n",
      "+--------+-----+\n",
      "|divorced|  622|\n",
      "| married| 2755|\n",
      "|  single| 1912|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_df.select('marital','y').filter(bank_df.y == 'yes').groupBy('marital').count().show()                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffeb511",
   "metadata": {},
   "source": [
    "### 8.\tCheck if age and marital status together mattered for subscription to deposit scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6fd9c229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+\n",
      "|age| marital|count|\n",
      "+---+--------+-----+\n",
      "| 18|  single|    7|\n",
      "| 19|  single|   11|\n",
      "| 20|  single|   14|\n",
      "| 20| married|    1|\n",
      "| 21|  single|   21|\n",
      "| 21| married|    1|\n",
      "| 22|  single|   40|\n",
      "| 23| married|    2|\n",
      "| 23|  single|   42|\n",
      "| 24|  single|   58|\n",
      "| 24| married|   10|\n",
      "| 25| married|   14|\n",
      "| 25|  single|   99|\n",
      "| 26| married|   13|\n",
      "| 26|  single|  121|\n",
      "| 27| married|   29|\n",
      "| 27|  single|  110|\n",
      "| 27|divorced|    2|\n",
      "| 28| married|   20|\n",
      "| 28|  single|  138|\n",
      "+---+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_df.select('age','marital','y')\\\n",
    "        .filter(bank_df.y == 'yes').groupBy('age','marital')\\\n",
    "        .count().orderBy('age').show()                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a19436e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
