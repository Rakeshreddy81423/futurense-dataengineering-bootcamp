{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e6f242",
   "metadata": {},
   "source": [
    "# Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f82e9a",
   "metadata": {},
   "source": [
    "## Assignment - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f5c3e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f004e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa882a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"SparkApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4454bdca",
   "metadata": {},
   "source": [
    "# Find min and max temperatures in given weather_data\n",
    "### *The data is seperated by one or more spaces. So first transform the data and do the calculations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2d15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = \"D:/futurense_hadoop-pyspark/labs/dataset/weather/weather_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2f0112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['WBANNO',\n",
    " 'LST_DATE',\n",
    " 'CRX_VN',\n",
    " 'LONGITUDE',\n",
    " 'LATITUDE',\n",
    " 'T_DAILY_MAX',\n",
    " 'T_DAILY_MIN',\n",
    " 'T_DAILY_MEAN',\n",
    " 'T_DAILY_AVG',\n",
    " 'P_DAILY_CALC',\n",
    " 'SOLARAD_DAILY',\n",
    " 'SUR_TEMP_DAILY_TYPE',\n",
    " 'SUR_TEMP_DAILY_MAX',\n",
    " 'SUR_TEMP_DAILY_MIN',\n",
    " 'SUR_TEMP_DAILY_AVG',\n",
    " 'RH_DAILY_MAX',\n",
    " 'RH_DAILY_MIN',\n",
    " 'RH_DAILY_AVG',\n",
    " 'SOIL_MOISTURE_5_DAILY',\n",
    " 'SOIL_MOISTURE_10_DAILY',\n",
    " 'SOIL_MOISTURE_20_DAILY',\n",
    " 'SOIL_MOISTURE_50_DAILY',\n",
    " 'SOIL_MOISTURE_100_DAILY',\n",
    " 'SOIL_TEMP_5_DAILY',\n",
    " 'SOIL_TEMP_10_DAILY',\n",
    " 'SOIL_TEMP_20_DAILY',\n",
    " 'SOIL_TEMP_50_DAILY',\n",
    " 'SOIL_TEMP_100_DAILY']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d14c98",
   "metadata": {},
   "source": [
    "### First read the data remove extra spaces and make it as comma seperated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e42ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.load(path,format=\"csv\")\n",
    "\n",
    "#df = data.withColumn(\"values\", regexp_replace(data.values, \"\\s+\", \",\")).withColumn(\"values\",split(data.value,\",\"))\n",
    "\n",
    "df = data.withColumn(\"_c0\",regexp_replace(data._c0,\"\\s+\",\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8d400",
   "metadata": {},
   "source": [
    "### Split the data based on ',' and store values in respective columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0d2d7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|Min_temp|max_temp|\n",
      "+--------+--------+\n",
      "|    -7.9|    36.0|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "split_data = df.select(split(df._c0, \",\").alias(\"data\"))\n",
    "\n",
    "\n",
    "converted_data = split_data.select(\n",
    "    *[split_data.data.getItem(idx).alias(columns[idx]) for idx in range(len(columns))])\n",
    "    \n",
    "\n",
    "#select the required the columns and type cast them into required datatype     \n",
    "min_max_df = converted_data.select(col(\"T_DAILY_MAX\").cast(FloatType()).alias(\"T_DAILY_MAX\"),col(\"T_DAILY_MIN\").cast(FloatType()).alias(\"T_DAILY_MIN\"))\n",
    "\n",
    "# find the min from the daily_min and max from daily_max\n",
    "min_max_df.agg(min(\"T_DAILY_MIN\").alias(\"Min_temp\"),max(\"T_DAILY_MAX\").alias(\"max_temp\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b3a89",
   "metadata": {},
   "source": [
    "### Find the max and min temperatures in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "37d76b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------+\n",
      "|MONTH|Min_temp|Max_temp|\n",
      "+-----+--------+--------+\n",
      "|  May|    14.3|    31.1|\n",
      "|  Jun|     0.0|    33.6|\n",
      "|  Feb|    -3.5|    26.6|\n",
      "|  Mar|    -3.2|    29.1|\n",
      "|  Jan|    -7.9|    26.5|\n",
      "|  Apr|     8.0|    30.8|\n",
      "|  Jul|    19.8|    36.0|\n",
      "+-----+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "\n",
    "def find_month_name(month_num):\n",
    "    return months[int(month_num) - 1]\n",
    "\n",
    "month_df = udf(find_month_name,StringType())\n",
    "\n",
    "\n",
    "df = converted_data.withColumn('MONTH',month_df(substring('LST_DATE',5,2)))\\\n",
    "                   .select(\n",
    "                            col('MONTH'),col(\"T_DAILY_MAX\").cast(FloatType()).alias(\"T_DAILY_MAX\"),\n",
    "                            col(\"T_DAILY_MIN\").cast(FloatType()).alias(\"T_DAILY_MIN\")\n",
    "                          )\n",
    "\n",
    "df.groupBy('MONTH').agg(min('T_DAILY_MIN').alias('Min_temp'),max('T_DAILY_MAX').alias('Max_temp')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab9465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a775f71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e41efef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
